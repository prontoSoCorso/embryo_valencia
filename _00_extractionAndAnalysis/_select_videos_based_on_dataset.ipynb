{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69e8f5b9",
   "metadata": {},
   "source": [
    "## Select videos in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57f17e11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 168 rows.\n",
      "Indexing folders in /home/phd2/Documenti/embryo/marilena_videos/extracted_equatorial_frames...\n",
      "Found 259 source folders.\n",
      "\n",
      "Starting processing...\n",
      "Processed 10 videos (Last: D2018.12.21_S02510_I0106_D_2 -> 96 frames, t0=0.0h)\n",
      "Processed 20 videos (Last: D2019.05.26_S01883_I0406_D_11 -> 93 frames, t0=0.0h)\n",
      "Processed 30 videos (Last: D2021.09.20_S02522_I0406_D_1 -> 89 frames, t0=0.0h)\n",
      "Processed 40 videos (Last: D2021.09.22_S00966_I0758_D_6 -> 93 frames, t0=0.0h)\n",
      "Processed 50 videos (Last: D2019.06.20_S01903_I0406_D_2 -> 93 frames, t0=0.0h)\n",
      "Processed 60 videos (Last: D2017.09.15_S0770_I631_5 -> 91 frames, t0=0.0h)\n",
      "Processed 70 videos (Last: D2019.03.14_S00126_I0758_D_5 -> 88 frames, t0=0.0h)\n",
      "Processed 80 videos (Last: D2020.08.03_S02162_I0406_D_4 -> 89 frames, t0=0.0h)\n",
      "Processed 90 videos (Last: D2016.11.15_S1896_I106_7 -> 466 frames, t0=0.0h)\n",
      "Processed 100 videos (Last: D2019.02.15_S01533_I0057_P_4 -> 575 frames, t0=0.0h)\n",
      "Processed 110 videos (Last: D2021.07.10_S00925_I3026_P_10 -> 521 frames, t0=22.39h)\n",
      "Processed 120 videos (Last: D2021.09.23_S01052_I3026_P_6 -> 757 frames, t0=0.0h)\n",
      "Processed 130 videos (Last: D2018.09.18_S01711_I0406_D_4 -> 459 frames, t0=0.0h)\n",
      "Processed 140 videos (Last: D2019.03.14_S01586_I0057_P_1 -> 580 frames, t0=0.0h)\n",
      "Processed 150 videos (Last: D2021.07.10_S00925_I3026_P_1 -> 636 frames, t0=0.0h)\n",
      "Processed 160 videos (Last: D2024.07.10_S04123_I0057_P_2 -> 692 frames, t0=0.0h)\n",
      "------------------------------\n",
      "Process Complete.\n",
      "Successfully Processed: 168\n",
      "Skipped (Dest Exists):  0\n",
      "Missing Source Folders: 0\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# ================= CONFIGURATION =================\n",
    "# Path to your CSV dataset\n",
    "CSV_PATH = \"/home/phd2/Scrivania/CorsoRepo/embryo_valencia/datasets/dataset_final_merged.csv\"\n",
    "\n",
    "# Root directory containing the year folders (2016, 2017...) and frames\n",
    "SOURCE_ROOT = \"/home/phd2/Documenti/embryo/marilena_videos/extracted_equatorial_frames\"\n",
    "\n",
    "# Where you want the files to go\n",
    "DEST_ROOT = \"/home/phd2/Documenti/embryo/marilena_videos/final_videos\"\n",
    "\n",
    "# ================= HELPER FUNCTIONS =================\n",
    "\n",
    "def parse_filename(filename):\n",
    "    \"\"\"\n",
    "    Parses a filename to extract frame number and time.\n",
    "    Expected format: D..._Frame_Z_Timeh.jpg\n",
    "    Example: D2021..._P_1_37_0_6.85h.jpg\n",
    "    \n",
    "    Returns:\n",
    "        dict: {'frame': int, 'time': float, 'parts': list} or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Remove extension\n",
    "        name_no_ext, ext = os.path.splitext(filename)\n",
    "        parts = name_no_ext.split('_')\n",
    "        \n",
    "        if len(parts) < 3:\n",
    "            return None\n",
    "            \n",
    "        # Extract Frame (3rd from last)\n",
    "        frame_str = parts[-3]\n",
    "        if not frame_str.isdigit():\n",
    "            return None\n",
    "        frame_num = int(frame_str)\n",
    "        \n",
    "        # Extract Time (last part)\n",
    "        # It usually ends with 'h', e.g. \"6.85h\"\n",
    "        time_str = parts[-1]\n",
    "        if time_str.lower().endswith('h'):\n",
    "            time_val_str = time_str[:-1]\n",
    "        else:\n",
    "            time_val_str = time_str\n",
    "            \n",
    "        # Replace comma just in case\n",
    "        time_val = float(time_val_str.replace(',', '.'))\n",
    "        \n",
    "        return {\n",
    "            'filename': filename,\n",
    "            'frame': frame_num,\n",
    "            'time': time_val,\n",
    "            'parts': parts,\n",
    "            'ext': ext\n",
    "        }\n",
    "    except Exception:\n",
    "        # If parsing fails (e.g. weird file), return None to skip\n",
    "        return None\n",
    "\n",
    "def construct_new_filename(info, t0):\n",
    "    \"\"\"\n",
    "    Reconstructs the filename with the shifted time.\n",
    "    New Time = Old Time - t0\n",
    "    \"\"\"\n",
    "    new_time = info['time'] - t0\n",
    "    # Ensure non-negative (just in case of float weirdness, though logic prevents it)\n",
    "    if new_time < 0: new_time = 0.0\n",
    "    \n",
    "    # Format: original parts except the last one\n",
    "    base_parts = info['parts'][:-1]\n",
    "    \n",
    "    # Reconstruct last part: \"0.25h\"\n",
    "    new_time_str = f\"{new_time:.2f}h\"\n",
    "    \n",
    "    new_name_no_ext = \"_\".join(base_parts) + \"_\" + new_time_str\n",
    "    return new_name_no_ext + info['ext']\n",
    "\n",
    "# ================= MAIN SCRIPT =================\n",
    "\n",
    "def main():\n",
    "    # 1. Load the Dataset\n",
    "    try:\n",
    "        # Using csv read\n",
    "        df = pd.read_csv(CSV_PATH, sep=',') \n",
    "        print(f\"Loaded dataset with {len(df)} rows.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading CSV: {e}\")\n",
    "        return\n",
    "\n",
    "    # Check columns\n",
    "    required_cols = ['dish_well', 'Note', 'start frame', 'end frame']\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            print(f\"Error: CSV is missing column '{col}'\")\n",
    "            return\n",
    "\n",
    "    # 2. Index the Source Directory\n",
    "    print(f\"Indexing folders in {SOURCE_ROOT}...\")\n",
    "    source_map = {}\n",
    "    for root, dirs, files in os.walk(SOURCE_ROOT):\n",
    "        for dirname in dirs:\n",
    "            source_map[dirname] = os.path.join(root, dirname)\n",
    "    print(f\"Found {len(source_map)} source folders.\")\n",
    "\n",
    "    # 3. Process\n",
    "    success_count = 0\n",
    "    missing_count = 0\n",
    "    skipped_count = 0\n",
    "    \n",
    "    print(\"\\nStarting processing...\")\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        dish_id = str(row['dish_well']).strip()\n",
    "        category = str(row['Note']).strip()\n",
    "        \n",
    "        # Parse start/end frames (Handle NaNs)\n",
    "        try:\n",
    "            start_lim = int(row['start frame']) if pd.notna(row['start frame']) else 1\n",
    "        except: start_lim = 1\n",
    "            \n",
    "        try:\n",
    "            end_lim = int(row['end frame']) if pd.notna(row['end frame']) else 999999\n",
    "        except: end_lim = 999999\n",
    "\n",
    "        # Handle bad categories\n",
    "        if category.lower() in ['nan', 'none', '']:\n",
    "            category = \"Uncategorized\"\n",
    "\n",
    "        dest_folder = os.path.join(DEST_ROOT, category, dish_id)\n",
    "\n",
    "        # Check if source exists\n",
    "        if dish_id in source_map:\n",
    "            src_folder = source_map[dish_id]\n",
    "            \n",
    "            # Destination logic\n",
    "            if not os.path.exists(dest_folder):\n",
    "                try:\n",
    "                    os.makedirs(dest_folder, exist_ok=True)\n",
    "                    \n",
    "                    # --- STEP 1: SCAN & FILTER ---\n",
    "                    all_files = sorted([f for f in os.listdir(src_folder) if f.lower().endswith('.jpg')])\n",
    "                    \n",
    "                    valid_frames = []\n",
    "                    \n",
    "                    for f in all_files:\n",
    "                        info = parse_filename(f)\n",
    "                        if info is None: continue\n",
    "                        \n",
    "                        # Filter Logic\n",
    "                        if start_lim <= info['frame'] <= end_lim:\n",
    "                            valid_frames.append(info)\n",
    "                    \n",
    "                    # Sort by frame number (crucial for time alignment)\n",
    "                    valid_frames.sort(key=lambda x: x['frame'])\n",
    "                    \n",
    "                    if not valid_frames:\n",
    "                        print(f\"Warning: No valid frames found for {dish_id} in range {start_lim}-{end_lim}\")\n",
    "                        # Cleanup empty dir if created\n",
    "                        os.rmdir(dest_folder)\n",
    "                        continue\n",
    "\n",
    "                    # --- STEP 2: DETERMINE T0 ---\n",
    "                    # The first frame in our kept sequence defines the new time zero\n",
    "                    t0 = valid_frames[0]['time']\n",
    "                    \n",
    "                    # --- STEP 3: COPY & RENAME ---\n",
    "                    files_copied_count = 0\n",
    "                    for info in valid_frames:\n",
    "                        src_file = os.path.join(src_folder, info['filename'])\n",
    "                        \n",
    "                        # Calculate new name with shifted time\n",
    "                        new_name = construct_new_filename(info, t0)\n",
    "                        dest_file = os.path.join(dest_folder, new_name)\n",
    "                        \n",
    "                        shutil.copy2(src_file, dest_file)\n",
    "                        files_copied_count += 1\n",
    "                    \n",
    "                    success_count += 1\n",
    "                    if success_count % 10 == 0:\n",
    "                        print(f\"Processed {success_count} videos (Last: {dish_id} -> {files_copied_count} frames, t0={t0}h)\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {dish_id}: {e}\")\n",
    "            else:\n",
    "                skipped_count += 1\n",
    "        else:\n",
    "            # print(f\"MISSING: Source folder not found for ID: {dish_id}\")\n",
    "            missing_count += 1\n",
    "\n",
    "    # ================= SUMMARY =================\n",
    "    print(\"-\" * 30)\n",
    "    print(\"Process Complete.\")\n",
    "    print(f\"Successfully Processed: {success_count}\")\n",
    "    print(f\"Skipped (Dest Exists):  {skipped_count}\")\n",
    "    print(f\"Missing Source Folders: {missing_count}\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5203b62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embryoValenciaVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
