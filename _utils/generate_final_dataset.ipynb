{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "215bd492",
   "metadata": {},
   "source": [
    "## Improve original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b155cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURATION\n",
    "# ==========================================\n",
    "# Paths\n",
    "DATASET_1_PATH = \"/home/phd2/Scrivania/CorsoRepo/embryo_valencia/dataset.xlsx\"\n",
    "DATASET_2_PATH = \"/home/phd2/Scrivania/CorsoRepo/embryo_valencia/DB_MII_to_blasto.xlsx\"\n",
    "OUTPUT_PATH    = \"/home/phd2/Scrivania/CorsoRepo/embryo_valencia/dataset_final_merged.csv\"\n",
    "\n",
    "# Columns config\n",
    "NEW_COLUMNS = [\n",
    "    \"dish_well\",            # Unique ID\n",
    "    \"BLASTO_NY\",            # 0 = No, 1 = Yes\n",
    "    \"GV\",                   # -1=MII (Native), 0-2=IVM, 3=Rescue MII\n",
    "    \"sibling\",              # 1=MII (Native), 0=IVM/Rescue\n",
    "    \"timing_GVBD\",          # hours\n",
    "    \"timing_extrusion_PB\",  # hours\n",
    "    \"Note\"                  # Classification (e.g., GV_to_M2, rM2_to_blasto)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55bce00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. HELPER FUNCTIONS\n",
    "# ==========================================\n",
    "def extract_pdb_info(raw_string):\n",
    "    if pd.isna(raw_string): return \"\", \"\"\n",
    "    s = str(raw_string).strip()\n",
    "    match = re.search(r'(.*?\\.pdb)(.*)', s, re.IGNORECASE)\n",
    "    if match:\n",
    "        pdb_clean = match.group(1).strip().replace(\".pdb\", \"\").replace(\".PDB\", \"\")\n",
    "        remainder = match.group(2).strip()\n",
    "        return pdb_clean, remainder\n",
    "    else:\n",
    "        return s, \"\"\n",
    "\n",
    "def map_gv_numeric(stage_string):\n",
    "    if not stage_string or pd.isna(stage_string): return np.nan\n",
    "    s = stage_string.upper()\n",
    "    if \"MII\" in s: return 2\n",
    "    elif \"MI\" in s: return 1\n",
    "    elif \"GV\" in s: return 0\n",
    "    else: return np.nan\n",
    "\n",
    "def clean_time(val):\n",
    "    if pd.isna(val): return np.nan\n",
    "    s = str(val).strip().replace(',', '.')\n",
    "    if s in ['-', '']: return np.nan\n",
    "    try: return float(s)\n",
    "    except: return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5141088",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing Dataset 1: Sheet 1 (GVs) ---\n",
      "Sheet 1 processed: 96 rows.\n",
      "--- Processing Dataset 1: Sheet 2 (Siblings) ---\n",
      "Sheet 2 processed: 60 rows.\n",
      "--- Processing Dataset 2 (Rescue MII) ---\n",
      "Dataset 2 processed: 51 rows.\n",
      "\n",
      "Warning: 3 duplicate IDs found. Keeping first occurrence.\n",
      "\n",
      "=== DONE ===\n",
      "File saved to: /home/phd2/Scrivania/CorsoRepo/embryo_valencia/dataset_final_merged.csv\n",
      "\n",
      "Distribution of 'Note':\n",
      "Note\n",
      "GV_to_M2            47\n",
      "rM2_to_no_blasto    41\n",
      "M2_to_blasto        40\n",
      "GV_to_GV            36\n",
      "M2_to_no_blasto     20\n",
      "GV_to_M1            12\n",
      "rM2_to_blasto        8\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Preview:\n",
      "                  dish_well  BLASTO_NY  GV  sibling  timing_GVBD  \\\n",
      "0  D2016.11.14_S1895_I106_6          1   2        0          4.8   \n",
      "1  D2016.11.14_S1895_I106_7          0   2        0          4.8   \n",
      "2  D2017.09.15_S0770_I631_2          0   2        0          NaN   \n",
      "3  D2017.09.15_S0770_I631_3          1   2        0          NaN   \n",
      "4  D2017.09.15_S0770_I631_4          0   2        0          1.2   \n",
      "\n",
      "   timing_extrusion_PB      Note  \n",
      "0                 20.3  GV_to_M2  \n",
      "1                 16.1  GV_to_M2  \n",
      "2                 20.7  GV_to_M2  \n",
      "3                 16.9  GV_to_M2  \n",
      "4                 15.9  GV_to_M2  \n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. PROCESSING DATASET 1 - SHEET 1 (IVM/GVs)\n",
    "# ==========================================\n",
    "print(\"--- Processing Dataset 1: Sheet 1 (GVs) ---\")\n",
    "try:\n",
    "    df1 = pd.read_excel(DATASET_1_PATH, sheet_name=0, header=None)\n",
    "    \n",
    "    # Dynamic column finding\n",
    "    pdb_col_idx = -1\n",
    "    for col in df1.columns:\n",
    "        if df1[col].astype(str).str.contains(r'\\.pdb', case=False, na=False).sum() > 5:\n",
    "            pdb_col_idx = col\n",
    "            break\n",
    "            \n",
    "    if pdb_col_idx == -1: raise ValueError(\"Column .pdb not found in Sheet 1\")\n",
    "\n",
    "    df1_subset = df1.iloc[:, pdb_col_idx : pdb_col_idx + 5].copy()\n",
    "    df1_subset.columns = ['raw_combined', 'raw_well', 'raw_gvbd', 'raw_pb', 'raw_blasto']\n",
    "    df1_clean = df1_subset[df1_subset['raw_combined'].astype(str).str.contains(r'\\.pdb', case=False, na=False)].copy()\n",
    "    \n",
    "    # 1. Clean Name and Stage\n",
    "    extracted_data = df1_clean['raw_combined'].apply(extract_pdb_info)\n",
    "    df1_clean['clean_name'] = extracted_data.apply(lambda x: x[0])\n",
    "    df1_clean['stage_info'] = extracted_data.apply(lambda x: x[1])\n",
    "    \n",
    "    # 2. Logic Assignment (GV & Sibling)\n",
    "    df1_clean['GV'] = df1_clean['stage_info'].apply(map_gv_numeric)\n",
    "    df1_clean['sibling'] = 0\n",
    "    \n",
    "    # 3. Time and Blasto\n",
    "    df1_clean['well_clean'] = pd.to_numeric(df1_clean['raw_well'], errors='coerce').fillna(0).astype(int).astype(str)\n",
    "    df1_clean['timing_GVBD'] = df1_clean['raw_gvbd'].apply(clean_time)\n",
    "    df1_clean['timing_extrusion_PB'] = df1_clean['raw_pb'].apply(clean_time)\n",
    "    df1_clean['BLASTO_NY'] = pd.to_numeric(df1_clean['raw_blasto'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # 4. Generate Note\n",
    "    # Logic: GV=0 -> GV_to_GV, GV=1 -> GV_to_M1, GV=2 -> GV_to_M2\n",
    "    def get_ivm_note(gv_code):\n",
    "        if gv_code == 0: return \"GV_to_GV\"\n",
    "        elif gv_code == 1: return \"GV_to_M1\"\n",
    "        elif gv_code == 2: return \"GV_to_M2\"\n",
    "        else: return \"Unknown_IVM\"\n",
    "    \n",
    "    df1_clean['Note'] = df1_clean['GV'].apply(get_ivm_note)\n",
    "\n",
    "    # 5. Create ID\n",
    "    df1_clean['dish_well'] = df1_clean['clean_name'] + \"_\" + df1_clean['well_clean']\n",
    "    \n",
    "    df1_final = df1_clean[NEW_COLUMNS]\n",
    "    print(f\"Sheet 1 processed: {len(df1_final)} rows.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error Sheet 1: {e}\")\n",
    "    df1_final = pd.DataFrame()\n",
    "\n",
    "# ==========================================\n",
    "# 4. PROCESSING DATASET 1 - SHEET 2 (Native MII)\n",
    "# ==========================================\n",
    "print(\"--- Processing Dataset 1: Sheet 2 (Siblings) ---\")\n",
    "try:\n",
    "    df2 = pd.read_excel(DATASET_1_PATH, sheet_name=1)\n",
    "    \n",
    "    cols = df2.columns.astype(str).str.lower()\n",
    "    c_pdb = df2.columns[cols.str.contains('pdb')][0]\n",
    "    c_well = df2.columns[cols.str.contains('well')][0]\n",
    "    c_blasto = df2.columns[cols.str.contains('blasto')][0]\n",
    "    \n",
    "    df2_clean = df2.copy()\n",
    "    \n",
    "    # 1. Cleaning\n",
    "    df2_clean['clean_name'] = df2_clean[c_pdb].apply(lambda x: str(x).replace('.pdb', '').strip())\n",
    "    df2_clean['well_clean'] = pd.to_numeric(df2_clean[c_well], errors='coerce').fillna(0).astype(int).astype(str)\n",
    "    \n",
    "    # 2. Logic\n",
    "    df2_clean['GV'] = -1\n",
    "    df2_clean['sibling'] = 1\n",
    "    df2_clean['BLASTO_NY'] = pd.to_numeric(df2_clean[c_blasto], errors='coerce').fillna(0).astype(int)\n",
    "    df2_clean['timing_GVBD'] = np.nan\n",
    "    df2_clean['timing_extrusion_PB'] = np.nan\n",
    "    \n",
    "    # 3. Generate Note\n",
    "    # Logic: M2 (Native) -> Blasto status\n",
    "    df2_clean['Note'] = df2_clean['BLASTO_NY'].apply(lambda x: \"M2_to_blasto\" if x == 1 else \"M2_to_no_blasto\")\n",
    "    \n",
    "    # 4. Create ID\n",
    "    df2_clean['dish_well'] = df2_clean['clean_name'] + \"_\" + df2_clean['well_clean']\n",
    "    \n",
    "    df2_final = df2_clean[NEW_COLUMNS]\n",
    "    print(f\"Sheet 2 processed: {len(df2_final)} rows.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error Sheet 2: {e}\")\n",
    "    df2_final = pd.DataFrame()\n",
    "\n",
    "# ==========================================\n",
    "# 5. PROCESSING DATASET 2 (Rescue MII)\n",
    "# ==========================================\n",
    "print(\"--- Processing Dataset 2 (Rescue MII) ---\")\n",
    "try:\n",
    "    raw_d2 = pd.read_excel(DATASET_2_PATH, header=None)\n",
    "    raw_list = raw_d2.iloc[:, 0].dropna().astype(str).tolist()\n",
    "    \n",
    "    parsed_rows = []\n",
    "    current_blasto_status = None \n",
    "    \n",
    "    for item in raw_list:\n",
    "        clean_item = item.strip()\n",
    "        \n",
    "        # Check Headers\n",
    "        if \"NO BLASTO\" in clean_item.upper():\n",
    "            current_blasto_status = 0\n",
    "            continue\n",
    "        elif \"BLASTO\" in clean_item.upper(): \n",
    "            current_blasto_status = 1\n",
    "            continue\n",
    "            \n",
    "        if current_blasto_status is not None:\n",
    "            new_id = re.sub(r'_wells_', '_', clean_item, flags=re.IGNORECASE)\n",
    "            \n",
    "            if 'D20' in new_id:\n",
    "                # Generate Note logic for Rescue MII\n",
    "                note_val = \"rM2_to_blasto\" if current_blasto_status == 1 else \"rM2_to_no_blasto\"\n",
    "                \n",
    "                parsed_rows.append({\n",
    "                    'dish_well': new_id,\n",
    "                    'BLASTO_NY': current_blasto_status,\n",
    "                    'GV': 3,          # Code for Rescue\n",
    "                    'sibling': 0,\n",
    "                    'timing_GVBD': np.nan,\n",
    "                    'timing_extrusion_PB': np.nan,\n",
    "                    'Note': note_val\n",
    "                })\n",
    "\n",
    "    df3_final = pd.DataFrame(parsed_rows)\n",
    "    for col in NEW_COLUMNS:\n",
    "        if col not in df3_final.columns:\n",
    "            df3_final[col] = np.nan\n",
    "            \n",
    "    df3_final = df3_final[NEW_COLUMNS]\n",
    "    print(f\"Dataset 2 processed: {len(df3_final)} rows.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error Dataset 2: {e}\")\n",
    "    df3_final = pd.DataFrame()\n",
    "\n",
    "# ==========================================\n",
    "# 6. MERGE AND EXPORT\n",
    "# ==========================================\n",
    "df_total = pd.concat([df1_final, df2_final, df3_final], ignore_index=True)\n",
    "\n",
    "df_total = df_total[df_total['dish_well'].notna()]\n",
    "df_total = df_total[df_total['dish_well'].astype(str).str.len() > 3]\n",
    "\n",
    "# Handle Duplicates\n",
    "duplicates = df_total['dish_well'].duplicated(keep='first')\n",
    "if duplicates.sum() > 0:\n",
    "    print(f\"\\nWarning: {duplicates.sum()} duplicate IDs found. Keeping first occurrence.\")\n",
    "    df_total = df_total[~duplicates]\n",
    "\n",
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "df_total.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(\"\\n=== DONE ===\")\n",
    "print(f\"File saved to: {OUTPUT_PATH}\")\n",
    "\n",
    "print(\"\\nDistribution of 'Note':\")\n",
    "print(df_total['Note'].value_counts())\n",
    "\n",
    "print(\"\\nPreview:\")\n",
    "print(df_total.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98901431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Preview:\n",
      "                        dish_well  BLASTO_NY  GV  sibling  timing_GVBD  \\\n",
      "10  D2019.02.15_S012161_I0631_D_1          0   2        0          0.6   \n",
      "11  D2019.02.15_S012161_I0631_D_2          0   2        0          5.6   \n",
      "12  D2019.02.15_S012161_I0631_D_5          1   2        0          4.6   \n",
      "13  D2019.02.15_S012161_I0631_D_6          0   2        0          NaN   \n",
      "14   D2019.03.14_S00126_I0758_D_3          0   2        0          7.1   \n",
      "15   D2019.03.14_S00126_I0758_D_6          0   2        0          9.6   \n",
      "16   D2019.03.14_S00126_I0758_D_7          0   2        0          9.2   \n",
      "17   D2019.05.26_S01883_I0406_D_9          0   2        0          1.4   \n",
      "18  D2019.05.26_S01883_I0406_D_10          0   2        0          2.4   \n",
      "19  D2019.05.26_S01883_I0406_D_11          0   2        0          0.9   \n",
      "\n",
      "    timing_extrusion_PB      Note  \n",
      "10                 13.8  GV_to_M2  \n",
      "11                 20.8  GV_to_M2  \n",
      "12                 20.6  GV_to_M2  \n",
      "13                 17.3  GV_to_M2  \n",
      "14                 21.4  GV_to_M2  \n",
      "15                 21.1  GV_to_M2  \n",
      "16                 14.7  GV_to_M2  \n",
      "17                 14.4  GV_to_M2  \n",
      "18                 16.2  GV_to_M2  \n",
      "19                 17.7  GV_to_M2  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nPreview:\")\n",
    "print(df_total.iloc[10:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embryoValenciaVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
