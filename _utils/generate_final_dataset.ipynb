{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "215bd492",
   "metadata": {},
   "source": [
    "## Improve original dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5141088",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "# ==========================================\n",
    "# 1. CONFIGURAZIONE\n",
    "# ==========================================\n",
    "DATASET_PATH = \"/home/phd2/Scrivania/CorsoRepo/embryo_valencia/dataset.xlsx\"\n",
    "DATASET_FINAL_PATH = \"/home/phd2/Scrivania/CorsoRepo/embryo_valencia/dataset_final.csv\"\n",
    "\n",
    "NEW_COLUMNS = [\n",
    "    \"dish_well\",            # ID univoco\n",
    "    \"BLASTO_NY\",            # 0/1\n",
    "    \"GV\",                   # -1 = MII nativo (Sheet 2), 0-2 = IVM (Sheet 1)\n",
    "    \"sibling\",              # 1 = MII nativo (Sheet 2), 0 = IVM (Sheet 1)\n",
    "    \"timing_GVBD\",          # ore\n",
    "    \"timing_extrusion_PB\"   # ore\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "91147ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 2. FUNZIONI UTILI\n",
    "# ==========================================\n",
    "\n",
    "def extract_pdb_info(raw_string):\n",
    "    \"\"\"\n",
    "    Separa il nome del file PDB dallo stage.\n",
    "    \"\"\"\n",
    "    if pd.isna(raw_string): return \"\", \"\"\n",
    "    s = str(raw_string).strip()\n",
    "    match = re.search(r'(.*?\\.pdb)(.*)', s, re.IGNORECASE)\n",
    "    if match:\n",
    "        pdb_clean = match.group(1).strip().replace(\".pdb\", \"\").replace(\".PDB\", \"\")\n",
    "        remainder = match.group(2).strip()\n",
    "        return pdb_clean, remainder\n",
    "    else:\n",
    "        return s, \"\"\n",
    "\n",
    "def map_gv_numeric(stage_string):\n",
    "    \"\"\"\n",
    "    0: GV to GV\n",
    "    1: GV to MI\n",
    "    2: GV to MII\n",
    "    \"\"\"\n",
    "    if not stage_string or pd.isna(stage_string): return np.nan\n",
    "    s = stage_string.upper()\n",
    "    if \"MII\" in s: return 2\n",
    "    elif \"MI\" in s: return 1\n",
    "    elif \"GV\" in s: return 0\n",
    "    else: return np.nan\n",
    "\n",
    "def clean_time(val):\n",
    "    if pd.isna(val): return np.nan\n",
    "    s = str(val).strip().replace(',', '.')\n",
    "    if s in ['-', '']: return np.nan\n",
    "    try: return float(s)\n",
    "    except: return np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58848604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Elaborazione Sheet 1 (GVs) ---\n",
      "Sheet 1 processato: 96 righe.\n",
      "--- Elaborazione Sheet 2 (Siblings) ---\n",
      "Sheet 2 processato: 60 righe.\n",
      "\n",
      "=== FATTO ===\n",
      "File salvato in: /home/phd2/Scrivania/CorsoRepo/embryo_valencia/dataset_final.csv\n",
      "\n",
      "Distribuzione GV (dovresti vedere -1, 0, 1, 2):\n",
      "GV\n",
      "-1    60\n",
      " 2    47\n",
      " 0    37\n",
      " 1    12\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribuzione Sibling (dovresti vedere 0 e 1):\n",
      "sibling\n",
      "0    96\n",
      "1    60\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Anteprima dati:\n",
      "                  dish_well  BLASTO_NY  GV  sibling  timing_GVBD  \\\n",
      "0  D2016.11.14_S1895_I106_6          1   2        0          4.8   \n",
      "1  D2016.11.14_S1895_I106_7          0   2        0          4.8   \n",
      "2  D2017.09.15_S0770_I631_2          0   2        0          NaN   \n",
      "3  D2017.09.15_S0770_I631_3          1   2        0          NaN   \n",
      "4  D2017.09.15_S0770_I631_4          0   2        0          1.2   \n",
      "\n",
      "   timing_extrusion_PB  \n",
      "0                 20.3  \n",
      "1                 16.1  \n",
      "2                 20.7  \n",
      "3                 16.9  \n",
      "4                 15.9  \n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 3. ELABORAZIONE SHEET 1 (IVM / GVs)\n",
    "# ==========================================\n",
    "print(\"--- Elaborazione Sheet 1 (GVs) ---\")\n",
    "try:\n",
    "    df1 = pd.read_excel(DATASET_PATH, sheet_name=0, header=None)\n",
    "    \n",
    "    # Trova colonna PDB\n",
    "    pdb_col_idx = -1\n",
    "    for col in df1.columns:\n",
    "        if df1[col].astype(str).str.contains(r'\\.pdb', case=False, na=False).sum() > 5:\n",
    "            pdb_col_idx = col\n",
    "            break\n",
    "            \n",
    "    if pdb_col_idx == -1: raise ValueError(\"Colonna .pdb non trovata in Sheet 1\")\n",
    "\n",
    "    # Estrai subset colonne\n",
    "    df1_subset = df1.iloc[:, pdb_col_idx : pdb_col_idx + 5].copy()\n",
    "    df1_subset.columns = ['raw_combined', 'raw_well', 'raw_gvbd', 'raw_pb', 'raw_blasto']\n",
    "    df1_clean = df1_subset[df1_subset['raw_combined'].astype(str).str.contains(r'\\.pdb', case=False, na=False)].copy()\n",
    "    \n",
    "    # 1. Pulizia Nome e Stage\n",
    "    extracted_data = df1_clean['raw_combined'].apply(extract_pdb_info)\n",
    "    df1_clean['clean_name'] = extracted_data.apply(lambda x: x[0])\n",
    "    df1_clean['stage_info'] = extracted_data.apply(lambda x: x[1])\n",
    "    \n",
    "    # 2. Assegnazione GV (0, 1, 2)\n",
    "    df1_clean['GV'] = df1_clean['stage_info'].apply(map_gv_numeric)\n",
    "    \n",
    "    # 3. Assegnazione Sibling (Regola: Sheet 1 = 0)\n",
    "    df1_clean['sibling'] = 0\n",
    "    \n",
    "    # 4. Altre conversioni\n",
    "    df1_clean['well_clean'] = pd.to_numeric(df1_clean['raw_well'], errors='coerce').fillna(0).astype(int).astype(str)\n",
    "    df1_clean['timing_GVBD'] = df1_clean['raw_gvbd'].apply(clean_time)\n",
    "    df1_clean['timing_extrusion_PB'] = df1_clean['raw_pb'].apply(clean_time)\n",
    "    df1_clean['BLASTO_NY'] = pd.to_numeric(df1_clean['raw_blasto'], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    df1_final = df1_clean[['clean_name', 'well_clean', 'GV', 'sibling', 'BLASTO_NY', 'timing_GVBD', 'timing_extrusion_PB']]\n",
    "    print(f\"Sheet 1 processato: {len(df1_final)} righe.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Errore Sheet 1: {e}\")\n",
    "    df1_final = pd.DataFrame()\n",
    "\n",
    "# ==========================================\n",
    "# 4. ELABORAZIONE SHEET 2 (MII / Siblings)\n",
    "# ==========================================\n",
    "print(\"--- Elaborazione Sheet 2 (Siblings) ---\")\n",
    "try:\n",
    "    df2 = pd.read_excel(DATASET_PATH, sheet_name=1)\n",
    "    \n",
    "    cols = df2.columns.astype(str).str.lower()\n",
    "    c_pdb = df2.columns[cols.str.contains('pdb')][0]\n",
    "    c_well = df2.columns[cols.str.contains('well')][0]\n",
    "    c_blasto = df2.columns[cols.str.contains('blasto')][0]\n",
    "    \n",
    "    df2_clean = df2.copy()\n",
    "    \n",
    "    # 1. Pulizia Nome\n",
    "    df2_clean['clean_name'] = df2_clean[c_pdb].apply(lambda x: str(x).replace('.pdb', '').strip())\n",
    "    df2_clean['well_clean'] = pd.to_numeric(df2_clean[c_well], errors='coerce').fillna(0).astype(int).astype(str)\n",
    "    \n",
    "    # 2. Assegnazione GV (Regola: Sheet 2 = -1)\n",
    "    df2_clean['GV'] = -1\n",
    "    \n",
    "    # 3. Assegnazione Sibling (Regola: Sheet 2 = 1)\n",
    "    df2_clean['sibling'] = 1\n",
    "    \n",
    "    # 4. Altre conversioni\n",
    "    df2_clean['BLASTO_NY'] = pd.to_numeric(df2_clean[c_blasto], errors='coerce').fillna(0).astype(int)\n",
    "    df2_clean['timing_GVBD'] = np.nan\n",
    "    df2_clean['timing_extrusion_PB'] = np.nan\n",
    "    \n",
    "    df2_final = df2_clean[['clean_name', 'well_clean', 'GV', 'sibling', 'BLASTO_NY', 'timing_GVBD', 'timing_extrusion_PB']]\n",
    "    print(f\"Sheet 2 processato: {len(df2_final)} righe.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Errore Sheet 2: {e}\")\n",
    "    df2_final = pd.DataFrame()\n",
    "\n",
    "# ==========================================\n",
    "# 5. MERGE E SALVATAGGIO\n",
    "# ==========================================\n",
    "\n",
    "df_total = pd.concat([df1_final, df2_final], ignore_index=True)\n",
    "\n",
    "# Creazione ID Univoco\n",
    "df_total['dish_well'] = df_total['clean_name'] + \"_\" + df_total['well_clean']\n",
    "\n",
    "# Selezione e pulizia finale\n",
    "df_output = df_total[NEW_COLUMNS]\n",
    "df_output = df_output[df_output['dish_well'].str.len() > 3] # Rimuove righe vuote\n",
    "\n",
    "# Salvataggio\n",
    "os.makedirs(os.path.dirname(DATASET_FINAL_PATH), exist_ok=True)\n",
    "df_output.to_csv(DATASET_FINAL_PATH, index=False)\n",
    "\n",
    "print(\"\\n=== FATTO ===\")\n",
    "print(f\"File salvato in: {DATASET_FINAL_PATH}\")\n",
    "print(\"\\nDistribuzione GV (dovresti vedere -1, 0, 1, 2):\")\n",
    "print(df_output['GV'].value_counts())\n",
    "print(\"\\nDistribuzione Sibling (dovresti vedere 0 e 1):\")\n",
    "print(df_output['sibling'].value_counts())\n",
    "print(\"\\nAnteprima dati:\")\n",
    "print(df_output.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b29e5a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embryoValenciaVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
